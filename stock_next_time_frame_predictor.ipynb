{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc45a498-9c5a-46b8-b0c2-0cba4b368e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install Requirments (Updated on 10/2/2024, streamlit 1.39.0)\n",
    "# !pip3 uninstall pandas pyarrow fireducks numpy -y\n",
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from yfinance import Ticker\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "import os\n",
    "# Set logging to suppress unwanted messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress INFO, WARNING, and ERROR logs\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN optimizations\n",
    "\n",
    "# Limit TensorFlow to use the first GPU (optional, based on your setup)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)  # Prevent memory pre-allocation\n",
    "        print(\"Using GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error initializing GPU:\", e)\n",
    "else:\n",
    "    print(\"No GPU detected. TensorFlow will use the CPU.\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.CRITICAL)\n",
    "\n",
    "from src import modules as f # f is for function\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae92876c-d015-403e-8cb5-3d49037ee40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from yfinance import Ticker\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "\n",
    "# Suppress TensorFlow INFO, WARNING, and ERROR logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Set TensorFlow log level\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN optimizations\n",
    "\n",
    "# Override logging filter to block all TensorFlow logs\n",
    "class BlockAllFilter(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        return False  # Prevent any logs from being processed\n",
    "\n",
    "# Apply the filter to TensorFlow and absl logging\n",
    "logging.getLogger(\"tensorflow\").addFilter(BlockAllFilter())\n",
    "logging.getLogger(\"absl\").addFilter(BlockAllFilter())\n",
    "\n",
    "# Limit TensorFlow to use the first GPU (if available)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)  # Prevent memory pre-allocation\n",
    "        print(\"Using GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error initializing GPU:\", e)\n",
    "else:\n",
    "    print(\"No GPU detected. TensorFlow will use the CPU.\")\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4821df5e-9e25-4463-83ed-80f7c8d2b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import modules as f # f is for function\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61147f2",
   "metadata": {},
   "source": [
    "### Download, Transform, and Modeling All in One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b1f5a4f-5fec-4117-b4fd-85444293245f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 5m Interval Timestamp: 2024-12-17 03:45:24 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>up</td>\n",
       "      <td>static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kelly_1:2.5</th>\n",
       "      <td>0.133632</td>\n",
       "      <td>0.137209</td>\n",
       "      <td>0.169392</td>\n",
       "      <td>0.113622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_up</th>\n",
       "      <td>0.437849</td>\n",
       "      <td>0.470545</td>\n",
       "      <td>0.429762</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_static</th>\n",
       "      <td>0.366735</td>\n",
       "      <td>0.295429</td>\n",
       "      <td>0.352356</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_down</th>\n",
       "      <td>0.195415</td>\n",
       "      <td>0.234026</td>\n",
       "      <td>0.217881</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.381166</td>\n",
       "      <td>0.383721</td>\n",
       "      <td>0.406709</td>\n",
       "      <td>0.366873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.363248</td>\n",
       "      <td>0.352564</td>\n",
       "      <td>0.41453</td>\n",
       "      <td>0.507495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.371991</td>\n",
       "      <td>0.367483</td>\n",
       "      <td>0.410582</td>\n",
       "      <td>0.425876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>[468.0, 467.0, 468.0]</td>\n",
       "      <td>[468.0, 467.0, 468.0]</td>\n",
       "      <td>[468.0, 467.0, 468.0]</td>\n",
       "      <td>[468.0, 467.0, 468.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           XGBoost       GradientBoosting  \\\n",
       "prediction                      up                     up   \n",
       "kelly_1:2.5               0.133632               0.137209   \n",
       "prob_up                   0.437849               0.470545   \n",
       "prob_static               0.366735               0.295429   \n",
       "prob_down                 0.195415               0.234026   \n",
       "precision                 0.381166               0.383721   \n",
       "recall                    0.363248               0.352564   \n",
       "f1                        0.371991               0.367483   \n",
       "support      [468.0, 467.0, 468.0]  [468.0, 467.0, 468.0]   \n",
       "\n",
       "                      RandomForest                    KNN  \n",
       "prediction                      up                 static  \n",
       "kelly_1:2.5               0.169392               0.113622  \n",
       "prob_up                   0.429762                   0.25  \n",
       "prob_static               0.352356                  0.375  \n",
       "prob_down                 0.217881                  0.375  \n",
       "precision                 0.406709               0.366873  \n",
       "recall                     0.41453               0.507495  \n",
       "f1                        0.410582               0.425876  \n",
       "support      [468.0, 467.0, 468.0]  [468.0, 467.0, 468.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 15m Interval Timestamp: 2024-12-17 03:45:28 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>down</td>\n",
       "      <td>static</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kelly_1:2.5</th>\n",
       "      <td>0.130645</td>\n",
       "      <td>0.190625</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.165385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_up</th>\n",
       "      <td>0.144338</td>\n",
       "      <td>0.212747</td>\n",
       "      <td>0.180863</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_static</th>\n",
       "      <td>0.401069</td>\n",
       "      <td>0.423778</td>\n",
       "      <td>0.406894</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_down</th>\n",
       "      <td>0.454594</td>\n",
       "      <td>0.363475</td>\n",
       "      <td>0.412244</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.379032</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.403846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.297468</td>\n",
       "      <td>0.515924</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>0.265823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.464183</td>\n",
       "      <td>0.28777</td>\n",
       "      <td>0.320611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>[158.0, 157.0, 158.0]</td>\n",
       "      <td>[158.0, 157.0, 158.0]</td>\n",
       "      <td>[158.0, 157.0, 158.0]</td>\n",
       "      <td>[158.0, 157.0, 158.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           XGBoost       GradientBoosting  \\\n",
       "prediction                    down                 static   \n",
       "kelly_1:2.5               0.130645               0.190625   \n",
       "prob_up                   0.144338               0.212747   \n",
       "prob_static               0.401069               0.423778   \n",
       "prob_down                 0.454594               0.363475   \n",
       "precision                 0.379032               0.421875   \n",
       "recall                    0.297468               0.515924   \n",
       "f1                        0.333333               0.464183   \n",
       "support      [158.0, 157.0, 158.0]  [158.0, 157.0, 158.0]   \n",
       "\n",
       "                      RandomForest                    KNN  \n",
       "prediction                    down                   down  \n",
       "kelly_1:2.5               0.066667               0.165385  \n",
       "prob_up                   0.180863                  0.125  \n",
       "prob_static               0.406894                   0.25  \n",
       "prob_down                 0.412244                  0.625  \n",
       "precision                 0.333333               0.403846  \n",
       "recall                    0.253165               0.265823  \n",
       "f1                         0.28777               0.320611  \n",
       "support      [158.0, 157.0, 158.0]  [158.0, 157.0, 158.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 1h Interval Timestamp: 2024-12-17 03:45:30 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kelly_1:2.5</th>\n",
       "      <td>0.281639</td>\n",
       "      <td>0.259355</td>\n",
       "      <td>0.263406</td>\n",
       "      <td>0.199722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_up</th>\n",
       "      <td>0.351211</td>\n",
       "      <td>0.264769</td>\n",
       "      <td>0.321133</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_static</th>\n",
       "      <td>0.386181</td>\n",
       "      <td>0.459729</td>\n",
       "      <td>0.385801</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_down</th>\n",
       "      <td>0.262608</td>\n",
       "      <td>0.275502</td>\n",
       "      <td>0.293066</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.486885</td>\n",
       "      <td>0.470968</td>\n",
       "      <td>0.473862</td>\n",
       "      <td>0.428373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.536101</td>\n",
       "      <td>0.527076</td>\n",
       "      <td>0.50722</td>\n",
       "      <td>0.555957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.510309</td>\n",
       "      <td>0.497445</td>\n",
       "      <td>0.489974</td>\n",
       "      <td>0.483896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>[552.0, 554.0, 552.0]</td>\n",
       "      <td>[552.0, 554.0, 552.0]</td>\n",
       "      <td>[552.0, 554.0, 552.0]</td>\n",
       "      <td>[552.0, 554.0, 552.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           XGBoost       GradientBoosting  \\\n",
       "prediction                  static                 static   \n",
       "kelly_1:2.5               0.281639               0.259355   \n",
       "prob_up                   0.351211               0.264769   \n",
       "prob_static               0.386181               0.459729   \n",
       "prob_down                 0.262608               0.275502   \n",
       "precision                 0.486885               0.470968   \n",
       "recall                    0.536101               0.527076   \n",
       "f1                        0.510309               0.497445   \n",
       "support      [552.0, 554.0, 552.0]  [552.0, 554.0, 552.0]   \n",
       "\n",
       "                      RandomForest                    KNN  \n",
       "prediction                  static                 static  \n",
       "kelly_1:2.5               0.263406               0.199722  \n",
       "prob_up                   0.321133                  0.375  \n",
       "prob_static               0.385801                  0.375  \n",
       "prob_down                 0.293066                   0.25  \n",
       "precision                 0.473862               0.428373  \n",
       "recall                     0.50722               0.555957  \n",
       "f1                        0.489974               0.483896  \n",
       "support      [552.0, 554.0, 552.0]  [552.0, 554.0, 552.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 1d Interval Timestamp: 2024-12-17 03:45:34 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>up</td>\n",
       "      <td>down</td>\n",
       "      <td>down</td>\n",
       "      <td>up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kelly_1:2.5</th>\n",
       "      <td>-0.016129</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.09863</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_up</th>\n",
       "      <td>0.538674</td>\n",
       "      <td>0.214739</td>\n",
       "      <td>0.368325</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_static</th>\n",
       "      <td>0.206358</td>\n",
       "      <td>0.259862</td>\n",
       "      <td>0.238162</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_down</th>\n",
       "      <td>0.254968</td>\n",
       "      <td>0.525399</td>\n",
       "      <td>0.393513</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.274194</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>0.306122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.385714</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.220588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.261538</td>\n",
       "      <td>0.380282</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.25641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>[68.0, 70.0, 70.0]</td>\n",
       "      <td>[68.0, 70.0, 70.0]</td>\n",
       "      <td>[68.0, 70.0, 70.0]</td>\n",
       "      <td>[68.0, 70.0, 70.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        XGBoost    GradientBoosting        RandomForest  \\\n",
       "prediction                   up                down                down   \n",
       "kelly_1:2.5           -0.016129               0.125             0.09863   \n",
       "prob_up                0.538674            0.214739            0.368325   \n",
       "prob_static            0.206358            0.259862            0.238162   \n",
       "prob_down              0.254968            0.525399            0.393513   \n",
       "precision              0.274194               0.375            0.356164   \n",
       "recall                     0.25            0.385714            0.371429   \n",
       "f1                     0.261538            0.380282            0.363636   \n",
       "support      [68.0, 70.0, 70.0]  [68.0, 70.0, 70.0]  [68.0, 70.0, 70.0]   \n",
       "\n",
       "                            KNN  \n",
       "prediction                   up  \n",
       "kelly_1:2.5            0.028571  \n",
       "prob_up                   0.375  \n",
       "prob_static                0.25  \n",
       "prob_down                 0.375  \n",
       "precision              0.306122  \n",
       "recall                 0.220588  \n",
       "f1                      0.25641  \n",
       "support      [68.0, 70.0, 70.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U 1wk Interval Timestamp: 2024-12-17 03:45:35 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>up</td>\n",
       "      <td>static</td>\n",
       "      <td>up</td>\n",
       "      <td>static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kelly_1:2.5</th>\n",
       "      <td>-0.12</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>0.042105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_up</th>\n",
       "      <td>0.574516</td>\n",
       "      <td>0.216695</td>\n",
       "      <td>0.354733</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_static</th>\n",
       "      <td>0.070982</td>\n",
       "      <td>0.427668</td>\n",
       "      <td>0.315467</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_down</th>\n",
       "      <td>0.354501</td>\n",
       "      <td>0.355636</td>\n",
       "      <td>0.3298</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>[12.0, 13.0, 13.0]</td>\n",
       "      <td>[12.0, 13.0, 13.0]</td>\n",
       "      <td>[12.0, 13.0, 13.0]</td>\n",
       "      <td>[12.0, 13.0, 13.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        XGBoost    GradientBoosting        RandomForest  \\\n",
       "prediction                   up              static                  up   \n",
       "kelly_1:2.5               -0.12               -0.05           -0.166667   \n",
       "prob_up                0.574516            0.216695            0.354733   \n",
       "prob_static            0.070982            0.427668            0.315467   \n",
       "prob_down              0.354501            0.355636              0.3298   \n",
       "precision                   0.2                0.25            0.166667   \n",
       "recall                     0.25            0.230769            0.166667   \n",
       "f1                     0.222222                0.24            0.166667   \n",
       "support      [12.0, 13.0, 13.0]  [12.0, 13.0, 13.0]  [12.0, 13.0, 13.0]   \n",
       "\n",
       "                            KNN  \n",
       "prediction               static  \n",
       "kelly_1:2.5            0.042105  \n",
       "prob_up                    0.25  \n",
       "prob_static               0.625  \n",
       "prob_down                 0.125  \n",
       "precision              0.315789  \n",
       "recall                 0.461538  \n",
       "f1                        0.375  \n",
       "support      [12.0, 13.0, 13.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The test_size = 2 should be greater or equal to the number of classes = 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/stock_production/src/modules.py:559\u001b[0m, in \u001b[0;36mpredictions\u001b[0;34m(symbol)\u001b[0m\n\u001b[1;32m    549\u001b[0m intervals \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5m\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    550\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15m\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    551\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1h\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1mo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    555\u001b[0m             ]\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m interval \u001b[38;5;129;01min\u001b[39;00m intervals:\n\u001b[0;32m--> 559\u001b[0m     time_stamp, summary_table \u001b[38;5;241m=\u001b[39m \u001b[43mdl_tf_pd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_dl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# skip_dl=True on redo's\u001b[39;00m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minterval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Interval Timestamp: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_stamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    561\u001b[0m     col_headers \u001b[38;5;241m=\u001b[39m summary_table\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/Documents/github/stock_production/src/modules.py:538\u001b[0m, in \u001b[0;36mdl_tf_pd\u001b[0;34m(symbol, interval, skip_dl)\u001b[0m\n\u001b[1;32m    536\u001b[0m download(symbol, interval)\n\u001b[1;32m    537\u001b[0m transform(symbol, interval)\n\u001b[0;32m--> 538\u001b[0m curr_prediction, models, feature_names, classification_reports \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    539\u001b[0m predictions, prediction_probas \u001b[38;5;241m=\u001b[39m make_prediction(models, curr_prediction, feature_names)\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m time_stamp, predictions_summary(predictions, prediction_probas, classification_reports)\n",
      "File \u001b[0;32m~/Documents/github/stock_production/src/modules.py:450\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(symbol, interval)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Fit and evaluate the model\u001b[39;00m\n\u001b[1;32m    449\u001b[0m model \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 450\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# store model in models dictionary\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github/stock_production/pyenv/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/stock_production/pyenv/lib/python3.12/site-packages/sklearn/ensemble/_gb.py:684\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_no_change \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    676\u001b[0m     stratify \u001b[38;5;241m=\u001b[39m y \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    677\u001b[0m     (\n\u001b[1;32m    678\u001b[0m         X_train,\n\u001b[1;32m    679\u001b[0m         X_val,\n\u001b[1;32m    680\u001b[0m         y_train,\n\u001b[1;32m    681\u001b[0m         y_val,\n\u001b[1;32m    682\u001b[0m         sample_weight_train,\n\u001b[1;32m    683\u001b[0m         sample_weight_val,\n\u001b[0;32m--> 684\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_fraction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_train)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    694\u001b[0m             \u001b[38;5;66;03m# We choose to error here. The problem is that the init\u001b[39;00m\n\u001b[1;32m    695\u001b[0m             \u001b[38;5;66;03m# estimator would be trained on y, which has some missing\u001b[39;00m\n\u001b[1;32m    696\u001b[0m             \u001b[38;5;66;03m# classes now, so its predictions would not have the\u001b[39;00m\n\u001b[1;32m    697\u001b[0m             \u001b[38;5;66;03m# correct shape.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github/stock_production/pyenv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/github/stock_production/pyenv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2806\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2802\u001b[0m         CVClass \u001b[38;5;241m=\u001b[39m ShuffleSplit\n\u001b[1;32m   2804\u001b[0m     cv \u001b[38;5;241m=\u001b[39m CVClass(test_size\u001b[38;5;241m=\u001b[39mn_test, train_size\u001b[38;5;241m=\u001b[39mn_train, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m-> 2806\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marrays\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstratify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2808\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[1;32m   2810\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2811\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2812\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2813\u001b[0m     )\n\u001b[1;32m   2814\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/github/stock_production/pyenv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:1843\u001b[0m, in \u001b[0;36mBaseShuffleSplit.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m   1814\u001b[0m \n\u001b[1;32m   1815\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1840\u001b[0m \u001b[38;5;124;03mto an integer.\u001b[39;00m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1842\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m-> 1843\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github/stock_production/pyenv/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2265\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit._iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2261\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe train_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2262\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_train, n_classes)\n\u001b[1;32m   2263\u001b[0m     )\n\u001b[1;32m   2264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_test \u001b[38;5;241m<\u001b[39m n_classes:\n\u001b[0;32m-> 2265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe test_size = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be greater or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2267\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal to the number of classes = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_test, n_classes)\n\u001b[1;32m   2268\u001b[0m     )\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;66;03m# Find the sorted list of instances for each class:\u001b[39;00m\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;66;03m# (np.unique above performs a sort, so code is O(n logn) already)\u001b[39;00m\n\u001b[1;32m   2272\u001b[0m class_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(\n\u001b[1;32m   2273\u001b[0m     np\u001b[38;5;241m.\u001b[39margsort(y_indices, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmergesort\u001b[39m\u001b[38;5;124m\"\u001b[39m), np\u001b[38;5;241m.\u001b[39mcumsum(class_counts)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   2274\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: The test_size = 2 should be greater or equal to the number of classes = 3"
     ]
    }
   ],
   "source": [
    "f.predictions('u')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e774a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faffd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681aeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29e9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10080b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9032138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73486d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b90ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c246e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfe9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac48269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74260a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22751626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol='NVDA'\n",
    "interval='1d'\n",
    "\n",
    "# # Define Eastern Time Zone\n",
    "# eastern = pytz.timezone('US/Eastern')\n",
    "\n",
    "# # Get current time in Eastern Time Zone\n",
    "# eastern_time = datetime.now(eastern)\n",
    "\n",
    "# # Format the time to include hour, minute, and seconds\n",
    "# time_stamp = eastern_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# print(f'DL Time: {time_stamp}')\n",
    "\n",
    "# f.download(symbol, interval, period)\n",
    "f.transform(symbol, interval)\n",
    "curr_prediction, models, feature_names, classification_reports = f.model(symbol, interval)\n",
    "predictions, prediction_probas = f.make_prediction(models, curr_prediction, feature_names)\n",
    "\n",
    "f.predictions_summary(predictions, prediction_probas, classification_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['XGBoost'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3373277",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905656b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = sorted(zip(feature_names, models['XGBoost'].feature_importances_),\n",
    "                     key=lambda x: x[1], \n",
    "                     reverse=True\n",
    "                    )\n",
    "merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fb54a",
   "metadata": {},
   "source": [
    "### Hyperparameter Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a303ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def model(symbol, interval, search_type='none'):\n",
    "    # Load data\n",
    "    data = f.load_model_df(symbol, interval)\n",
    "    data.dropna(inplace=True, axis=0)\n",
    "    X = data.drop(columns=['direction'], axis=1)\n",
    "    y = data['direction']\n",
    "    \n",
    "    # Print column names to check for issues\n",
    "    print(\"Columns in X before preprocessing:\")\n",
    "    print(X.columns)\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    X = X.loc[:, ~X.columns.duplicated()]\n",
    "    \n",
    "    # Check if categorical_features are present in X\n",
    "    categorical_features = ['day_of_month', 'day_of_week', 'hour_of_day']\n",
    "    missing_features = [col for col in categorical_features if col not in X.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Missing categorical features: {missing_features}\")\n",
    "    \n",
    "    # Store current prediction data (last row)\n",
    "    curr_prediction = X.iloc[-1].copy()\n",
    "\n",
    "    # Drop last row from X and y to prevent the model from seeing it\n",
    "    X = X.iloc[:-1]\n",
    "    y = y.iloc[:-1]\n",
    "    \n",
    "    # Create the categorical transformer\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    \n",
    "    # Create the preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        force_int_remainder_cols=False # This will include all other columns in the transformed output\n",
    "    )\n",
    "    \n",
    "    # Define your models\n",
    "    models = {\n",
    "        'XGBoost': XGBClassifier(random_state=42, n_jobs=-1),\n",
    "        'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "        'GradientBoosting': GradientBoostingClassifier(random_state=42, validation_fraction=0.25, n_iter_no_change=31),\n",
    "        # 'LightGBM': LGBMClassifier(random_state=42,force_col_wise=True),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=7, p=1,weights='distance')\n",
    "    }\n",
    "    \n",
    "    # Hyperparameters to search\n",
    "    param_grids = {\n",
    "        'XGBoost': {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [3, 5, 7, 9],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2, 0.3]\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [None, 10, 20, 30],\n",
    "            'classifier__min_samples_split': [2, 5, 10, 13]\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'classifier__n_estimators': [100, 200, 300, 400],\n",
    "            'classifier__max_depth': [3, 5, 7, 13],\n",
    "            'classifier__le||arning_rate': [0.01, 0.1, 0.2, 0.5]\n",
    "        },\n",
    "        'KNN': {\n",
    "            'classifier__n_neighbors': [3, 5, 7, 13],\n",
    "            'classifier__weights': ['uniform', 'distance'],\n",
    "            'classifier__p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create a function to get feature names after transformation\n",
    "    def get_feature_names_out(column_transformer):\n",
    "        feature_names = []\n",
    "        for name, transformer, columns in column_transformer.transformers_:\n",
    "            if transformer == 'drop' or transformer == 'passthrough':\n",
    "                if transformer == 'passthrough':\n",
    "                    feature_names.extend(columns)\n",
    "                continue\n",
    "            if hasattr(transformer, 'get_feature_names_out'):\n",
    "                names = transformer.get_feature_names_out(columns)\n",
    "                feature_names.extend(names)\n",
    "            else:\n",
    "                feature_names.extend(columns)\n",
    "        return feature_names\n",
    "    \n",
    "    # Split data before preprocessing to avoid data leakage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit the preprocessor on training data\n",
    "    preprocessor.fit(X_train)\n",
    "    \n",
    "    # Transform training and test data\n",
    "    X_train_transformed = preprocessor.transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Get feature names after transformation\n",
    "    feature_names = get_feature_names_out(preprocessor)\n",
    "    \n",
    "    # Convert transformed data to DataFrame\n",
    "    X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "    X_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_names)\n",
    "    \n",
    "    # Transform curr_prediction\n",
    "    curr_prediction_transformed = preprocessor.transform(\n",
    "        curr_prediction.to_frame().T)\n",
    "    curr_prediction_transformed = pd.DataFrame(\n",
    "        curr_prediction_transformed, columns=feature_names)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Create a pipeline with the classifier\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        # Get the parameter grid for the current model\n",
    "        param_grid = param_grids.get(model_name, {})\n",
    "        \n",
    "        # Use GridSearchCV or RandomizedSearchCV\n",
    "        if search_type == 'grid' and param_grid:\n",
    "            search = GridSearchCV(\n",
    "                pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        elif search_type == 'random' and param_grid:\n",
    "            search = RandomizedSearchCV(\n",
    "                pipeline, param_grid, cv=5, scoring='accuracy',\n",
    "                n_jobs=-1, n_iter=10, random_state=42)\n",
    "        else:\n",
    "            search = pipeline\n",
    "        \n",
    "        # Fit the model\n",
    "        search.fit(X_train_transformed, y_train)\n",
    "        \n",
    "        # If using search, get the best estimator\n",
    "        if search_type in ['grid', 'random'] and param_grid:\n",
    "            best_model = search.best_estimator_\n",
    "            print(f\"Best parameters for {model_name}: {search.best_params_}\")\n",
    "            model = best_model.named_steps['classifier']\n",
    "        else:\n",
    "            model = search.named_steps['classifier']\n",
    "        \n",
    "        # Store the model\n",
    "        models[model_name] = model\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred = search.predict(X_test_transformed)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    return curr_prediction_transformed, models, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c358417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_prediction, models, feature_names = model('AMD', '5m', 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f7294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379dcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
