{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc3c8ff7",
   "metadata": {},
   "source": [
    "## Build Functions for ELT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "30a2670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Requirments (Updated on 10/2/2024, streamlit 1.39.0)\n",
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b487bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from yfinance import Ticker\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "import pprint\n",
    "\n",
    "from src import functions as f\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e7e3dcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-05 04:24:56\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob_no_change</th>\n",
       "      <th>prob_up</th>\n",
       "      <th>prob_down</th>\n",
       "      <th>kelly_criterion_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951470</td>\n",
       "      <td>0.035975</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>0.927205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779380</td>\n",
       "      <td>0.100786</td>\n",
       "      <td>0.119834</td>\n",
       "      <td>0.669070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.035390</td>\n",
       "      <td>0.019729</td>\n",
       "      <td>0.917323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  prediction  prob_no_change   prob_up  prob_down  \\\n",
       "0           XGBoost           0        0.750000  0.000000   0.250000   \n",
       "1      RandomForest           0        0.951470  0.035975   0.012554   \n",
       "2  GradientBoosting           0        0.779380  0.100786   0.119834   \n",
       "3               KNN           0        0.944882  0.035390   0.019729   \n",
       "\n",
       "   kelly_criterion_1_2  \n",
       "0             0.625000  \n",
       "1             0.927205  \n",
       "2             0.669070  \n",
       "3             0.917323  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.dl_tf_pd('NVDA','5m','1mo', skip_dl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e099aea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob_no_change</th>\n",
       "      <th>prob_up</th>\n",
       "      <th>prob_down</th>\n",
       "      <th>kelly_criterion_1_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951470</td>\n",
       "      <td>0.035975</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>0.927205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0</td>\n",
       "      <td>0.779380</td>\n",
       "      <td>0.100786</td>\n",
       "      <td>0.119834</td>\n",
       "      <td>0.669070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.944882</td>\n",
       "      <td>0.035390</td>\n",
       "      <td>0.019729</td>\n",
       "      <td>0.917323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model  prediction  prob_no_change   prob_up  prob_down  \\\n",
       "0           XGBoost           0        0.750000  0.000000   0.250000   \n",
       "1      RandomForest           0        0.951470  0.035975   0.012554   \n",
       "2  GradientBoosting           0        0.779380  0.100786   0.119834   \n",
       "3               KNN           0        0.944882  0.035390   0.019729   \n",
       "\n",
       "   kelly_criterion_1_2  \n",
       "0             0.625000  \n",
       "1             0.927205  \n",
       "2             0.669070  \n",
       "3             0.917323  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol='NVDA'\n",
    "interval='5m'\n",
    "period='1mo'\n",
    "\n",
    "# f.download(symbol, interval, period)\n",
    "f.transform(symbol, interval, period)\n",
    "curr_prediction, models, feature_names, classification_reports = f.model(symbol, interval)\n",
    "predictions, prediction_probas = f.make_prediction(models, curr_prediction, feature_names)\n",
    "f.predictions_summary(predictions, prediction_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "38305bb7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBClassifier': {'0': {'precision': 0.702928870292887,\n",
       "   'recall': 0.7601809954751131,\n",
       "   'f1-score': 0.7304347826086957,\n",
       "   'support': 221.0},\n",
       "  '1': {'precision': 0.8283828382838284,\n",
       "   'recall': 0.8019169329073482,\n",
       "   'f1-score': 0.814935064935065,\n",
       "   'support': 313.0},\n",
       "  '2': {'precision': 0.7731958762886598,\n",
       "   'recall': 0.7525083612040134,\n",
       "   'f1-score': 0.7627118644067796,\n",
       "   'support': 299.0},\n",
       "  'accuracy': 0.773109243697479,\n",
       "  'macro avg': {'precision': 0.7681691949551251,\n",
       "   'recall': 0.7715354298621583,\n",
       "   'f1-score': 0.7693605706501799,\n",
       "   'support': 833.0},\n",
       "  'weighted avg': {'precision': 0.7752901269242205,\n",
       "   'recall': 0.773109243697479,\n",
       "   'f1-score': 0.7737714402626941,\n",
       "   'support': 833.0}},\n",
       " 'RandomForestClassifier': {'0': {'precision': 0.6583333333333333,\n",
       "   'recall': 0.7149321266968326,\n",
       "   'f1-score': 0.6854663774403471,\n",
       "   'support': 221.0},\n",
       "  '1': {'precision': 0.7936507936507936,\n",
       "   'recall': 0.7987220447284346,\n",
       "   'f1-score': 0.7961783439490446,\n",
       "   'support': 313.0},\n",
       "  '2': {'precision': 0.7697841726618705,\n",
       "   'recall': 0.7157190635451505,\n",
       "   'f1-score': 0.7417677642980935,\n",
       "   'support': 299.0},\n",
       "  'accuracy': 0.7466986794717887,\n",
       "  'macro avg': {'precision': 0.7405894332153324,\n",
       "   'recall': 0.7431244116568059,\n",
       "   'f1-score': 0.7411374952291618,\n",
       "   'support': 833.0},\n",
       "  'weighted avg': {'precision': 0.7491834726353714,\n",
       "   'recall': 0.7466986794717887,\n",
       "   'f1-score': 0.7472754532959155,\n",
       "   'support': 833.0}},\n",
       " 'GradientBoostingClassifier': {'0': {'precision': 0.7119341563786008,\n",
       "   'recall': 0.7828054298642534,\n",
       "   'f1-score': 0.7456896551724138,\n",
       "   'support': 221.0},\n",
       "  '1': {'precision': 0.8419243986254296,\n",
       "   'recall': 0.7827476038338658,\n",
       "   'f1-score': 0.8112582781456954,\n",
       "   'support': 313.0},\n",
       "  '2': {'precision': 0.7591973244147158,\n",
       "   'recall': 0.7591973244147158,\n",
       "   'f1-score': 0.7591973244147158,\n",
       "   'support': 299.0},\n",
       "  'accuracy': 0.7743097238895558,\n",
       "  'macro avg': {'precision': 0.7710186264729154,\n",
       "   'recall': 0.7749167860376116,\n",
       "   'f1-score': 0.772048419244275,\n",
       "   'support': 833.0},\n",
       "  'weighted avg': {'precision': 0.7777428395311288,\n",
       "   'recall': 0.7743097238895558,\n",
       "   'f1-score': 0.7751755760536688,\n",
       "   'support': 833.0}},\n",
       " 'KNeighborsClassifier': {'0': {'precision': 0.578544061302682,\n",
       "   'recall': 0.6832579185520362,\n",
       "   'f1-score': 0.6265560165975104,\n",
       "   'support': 221.0},\n",
       "  '1': {'precision': 0.6573208722741433,\n",
       "   'recall': 0.6741214057507987,\n",
       "   'f1-score': 0.6656151419558359,\n",
       "   'support': 313.0},\n",
       "  '2': {'precision': 0.6932270916334662,\n",
       "   'recall': 0.5819397993311036,\n",
       "   'f1-score': 0.6327272727272727,\n",
       "   'support': 299.0},\n",
       "  'accuracy': 0.6434573829531812,\n",
       "  'macro avg': {'precision': 0.6430306750700971,\n",
       "   'recall': 0.6464397078779794,\n",
       "   'f1-score': 0.641632810426873,\n",
       "   'support': 833.0},\n",
       "  'weighted avg': {'precision': 0.6493092088452653,\n",
       "   'recall': 0.6434573829531812,\n",
       "   'f1-score': 0.6434476274257874,\n",
       "   'support': 833.0}}}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6c85d6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GradientBoostingClassifier': {'0': {'f1-score': 0.7456896551724138,\n",
      "                                      'precision': 0.7119341563786008,\n",
      "                                      'recall': 0.7828054298642534,\n",
      "                                      'support': 221.0},\n",
      "                                '1': {'f1-score': 0.8112582781456954,\n",
      "                                      'precision': 0.8419243986254296,\n",
      "                                      'recall': 0.7827476038338658,\n",
      "                                      'support': 313.0},\n",
      "                                '2': {'f1-score': 0.7591973244147158,\n",
      "                                      'precision': 0.7591973244147158,\n",
      "                                      'recall': 0.7591973244147158,\n",
      "                                      'support': 299.0},\n",
      "                                'accuracy': 0.7743097238895558,\n",
      "                                'macro avg': {'f1-score': 0.772048419244275,\n",
      "                                              'precision': 0.7710186264729154,\n",
      "                                              'recall': 0.7749167860376116,\n",
      "                                              'support': 833.0},\n",
      "                                'weighted avg': {'f1-score': 0.7751755760536688,\n",
      "                                                 'precision': 0.7777428395311288,\n",
      "                                                 'recall': 0.7743097238895558,\n",
      "                                                 'support': 833.0}},\n",
      " 'KNeighborsClassifier': {'0': {'f1-score': 0.6265560165975104,\n",
      "                                'precision': 0.578544061302682,\n",
      "                                'recall': 0.6832579185520362,\n",
      "                                'support': 221.0},\n",
      "                          '1': {'f1-score': 0.6656151419558359,\n",
      "                                'precision': 0.6573208722741433,\n",
      "                                'recall': 0.6741214057507987,\n",
      "                                'support': 313.0},\n",
      "                          '2': {'f1-score': 0.6327272727272727,\n",
      "                                'precision': 0.6932270916334662,\n",
      "                                'recall': 0.5819397993311036,\n",
      "                                'support': 299.0},\n",
      "                          'accuracy': 0.6434573829531812,\n",
      "                          'macro avg': {'f1-score': 0.641632810426873,\n",
      "                                        'precision': 0.6430306750700971,\n",
      "                                        'recall': 0.6464397078779794,\n",
      "                                        'support': 833.0},\n",
      "                          'weighted avg': {'f1-score': 0.6434476274257874,\n",
      "                                           'precision': 0.6493092088452653,\n",
      "                                           'recall': 0.6434573829531812,\n",
      "                                           'support': 833.0}},\n",
      " 'RandomForestClassifier': {'0': {'f1-score': 0.6854663774403471,\n",
      "                                  'precision': 0.6583333333333333,\n",
      "                                  'recall': 0.7149321266968326,\n",
      "                                  'support': 221.0},\n",
      "                            '1': {'f1-score': 0.7961783439490446,\n",
      "                                  'precision': 0.7936507936507936,\n",
      "                                  'recall': 0.7987220447284346,\n",
      "                                  'support': 313.0},\n",
      "                            '2': {'f1-score': 0.7417677642980935,\n",
      "                                  'precision': 0.7697841726618705,\n",
      "                                  'recall': 0.7157190635451505,\n",
      "                                  'support': 299.0},\n",
      "                            'accuracy': 0.7466986794717887,\n",
      "                            'macro avg': {'f1-score': 0.7411374952291618,\n",
      "                                          'precision': 0.7405894332153324,\n",
      "                                          'recall': 0.7431244116568059,\n",
      "                                          'support': 833.0},\n",
      "                            'weighted avg': {'f1-score': 0.7472754532959155,\n",
      "                                             'precision': 0.7491834726353714,\n",
      "                                             'recall': 0.7466986794717887,\n",
      "                                             'support': 833.0}},\n",
      " 'XGBClassifier': {'0': {'f1-score': 0.7304347826086957,\n",
      "                         'precision': 0.702928870292887,\n",
      "                         'recall': 0.7601809954751131,\n",
      "                         'support': 221.0},\n",
      "                   '1': {'f1-score': 0.814935064935065,\n",
      "                         'precision': 0.8283828382838284,\n",
      "                         'recall': 0.8019169329073482,\n",
      "                         'support': 313.0},\n",
      "                   '2': {'f1-score': 0.7627118644067796,\n",
      "                         'precision': 0.7731958762886598,\n",
      "                         'recall': 0.7525083612040134,\n",
      "                         'support': 299.0},\n",
      "                   'accuracy': 0.773109243697479,\n",
      "                   'macro avg': {'f1-score': 0.7693605706501799,\n",
      "                                 'precision': 0.7681691949551251,\n",
      "                                 'recall': 0.7715354298621583,\n",
      "                                 'support': 833.0},\n",
      "                   'weighted avg': {'f1-score': 0.7737714402626941,\n",
      "                                    'precision': 0.7752901269242205,\n",
      "                                    'recall': 0.773109243697479,\n",
      "                                    'support': 833.0}}}\n"
     ]
    }
   ],
   "source": [
    "# Pretty-print the dictionary\n",
    "pprint.pprint(classification_reports, width=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de450a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08058e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb6752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40c26ef2",
   "metadata": {},
   "source": [
    "## Kelly Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "66ada27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction = p / l - q / g\n",
    "# p = probability of success\n",
    "# q = 1 - p = probability or failure\n",
    "# l = % loss (ex: $10 -> $9 would mean l = .1)\n",
    "# g = % gain (ex: $10 -> $12 would mean g = .2)\n",
    "\n",
    "def kelly_c(p, l=1, g=2): # default l=1 and g=2 for 2 to 1 gain to loss\n",
    "    return p / l - (1 - p) / g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b4f09b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kelly_c(.75,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "83a4b5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kelly_c(.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fb54a",
   "metadata": {},
   "source": [
    "## Hyperparameter Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a303ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def model(symbol, interval, search_type='none'):\n",
    "    # Load data\n",
    "    data = f.load_model_df(symbol, interval)\n",
    "    data.dropna(inplace=True, axis=0)\n",
    "    X = data.drop(columns=['direction'], axis=1)\n",
    "    y = data['direction']\n",
    "    \n",
    "    # Print column names to check for issues\n",
    "    print(\"Columns in X before preprocessing:\")\n",
    "    print(X.columns)\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    X = X.loc[:, ~X.columns.duplicated()]\n",
    "    \n",
    "    # Check if categorical_features are present in X\n",
    "    categorical_features = ['day_of_month', 'day_of_week', 'hour_of_day']\n",
    "    missing_features = [col for col in categorical_features if col not in X.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Missing categorical features: {missing_features}\")\n",
    "    \n",
    "    # Store current prediction data (last row)\n",
    "    curr_prediction = X.iloc[-1].copy()\n",
    "\n",
    "    # Drop last row from X and y to prevent the model from seeing it\n",
    "    X = X.iloc[:-1]\n",
    "    y = y.iloc[:-1]\n",
    "    \n",
    "    # Create the categorical transformer\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    \n",
    "    # Create the preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        force_int_remainder_cols=False # This will include all other columns in the transformed output\n",
    "    )\n",
    "    \n",
    "    # Define your models\n",
    "    models = {\n",
    "        'XGBoost': XGBClassifier(random_state=42, n_jobs=-1),\n",
    "        'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "        'GradientBoosting': GradientBoostingClassifier(random_state=42, validation_fraction=0.25, n_iter_no_change=31),\n",
    "        # 'LightGBM': LGBMClassifier(random_state=42,force_col_wise=True),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=7, p=1,weights='distance')\n",
    "    }\n",
    "    \n",
    "    # Hyperparameters to search\n",
    "    param_grids = {\n",
    "        'XGBoost': {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [3, 5, 7, 9],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2, 0.3]\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [None, 10, 20, 30],\n",
    "            'classifier__min_samples_split': [2, 5, 10, 13]\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'classifier__n_estimators': [100, 200, 300, 400],\n",
    "            'classifier__max_depth': [3, 5, 7, 13],\n",
    "            'classifier__le||arning_rate': [0.01, 0.1, 0.2, 0.5]\n",
    "        },\n",
    "        'KNN': {\n",
    "            'classifier__n_neighbors': [3, 5, 7, 13],\n",
    "            'classifier__weights': ['uniform', 'distance'],\n",
    "            'classifier__p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create a function to get feature names after transformation\n",
    "    def get_feature_names_out(column_transformer):\n",
    "        feature_names = []\n",
    "        for name, transformer, columns in column_transformer.transformers_:\n",
    "            if transformer == 'drop' or transformer == 'passthrough':\n",
    "                if transformer == 'passthrough':\n",
    "                    feature_names.extend(columns)\n",
    "                continue\n",
    "            if hasattr(transformer, 'get_feature_names_out'):\n",
    "                names = transformer.get_feature_names_out(columns)\n",
    "                feature_names.extend(names)\n",
    "            else:\n",
    "                feature_names.extend(columns)\n",
    "        return feature_names\n",
    "    \n",
    "    # Split data before preprocessing to avoid data leakage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit the preprocessor on training data\n",
    "    preprocessor.fit(X_train)\n",
    "    \n",
    "    # Transform training and test data\n",
    "    X_train_transformed = preprocessor.transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Get feature names after transformation\n",
    "    feature_names = get_feature_names_out(preprocessor)\n",
    "    \n",
    "    # Convert transformed data to DataFrame\n",
    "    X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "    X_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_names)\n",
    "    \n",
    "    # Transform curr_prediction\n",
    "    curr_prediction_transformed = preprocessor.transform(\n",
    "        curr_prediction.to_frame().T)\n",
    "    curr_prediction_transformed = pd.DataFrame(\n",
    "        curr_prediction_transformed, columns=feature_names)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Create a pipeline with the classifier\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        # Get the parameter grid for the current model\n",
    "        param_grid = param_grids.get(model_name, {})\n",
    "        \n",
    "        # Use GridSearchCV or RandomizedSearchCV\n",
    "        if search_type == 'grid' and param_grid:\n",
    "            search = GridSearchCV(\n",
    "                pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        elif search_type == 'random' and param_grid:\n",
    "            search = RandomizedSearchCV(\n",
    "                pipeline, param_grid, cv=5, scoring='accuracy',\n",
    "                n_jobs=-1, n_iter=10, random_state=42)\n",
    "        else:\n",
    "            search = pipeline\n",
    "        \n",
    "        # Fit the model\n",
    "        search.fit(X_train_transformed, y_train)\n",
    "        \n",
    "        # If using search, get the best estimator\n",
    "        if search_type in ['grid', 'random'] and param_grid:\n",
    "            best_model = search.best_estimator_\n",
    "            print(f\"Best parameters for {model_name}: {search.best_params_}\")\n",
    "            model = best_model.named_steps['classifier']\n",
    "        else:\n",
    "            model = search.named_steps['classifier']\n",
    "        \n",
    "        # Store the model\n",
    "        models[model_name] = model\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred = search.predict(X_test_transformed)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    return curr_prediction_transformed, models, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c358417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_prediction, models, feature_names = model('AMD', '5m', 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f7294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379dcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
