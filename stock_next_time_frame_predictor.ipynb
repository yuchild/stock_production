{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc3c8ff7",
   "metadata": {},
   "source": [
    "## Build Functions for ELT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30a2670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Requirments (Updated on 10/2/2024, streamlit 1.39.0)\n",
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b487bd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from yfinance import Ticker\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "import pprint\n",
    "\n",
    "from src import functions as f\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61147f2",
   "metadata": {},
   "source": [
    "### Download, Transform, and Modeling All in One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e3dcad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m time_stamp, summary_table \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241m.\u001b[39mdl_tf_pd(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAAPL\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5m\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1mo\u001b[39m\u001b[38;5;124m'\u001b[39m, skip_dl\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_stamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m summary_table\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "time_stamp, summary_table = f.dl_tf_pd('AAPL','5m','1mo', skip_dl=False)\n",
    "print(f'{time_stamp}\\n')\n",
    "summary_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b512704a",
   "metadata": {},
   "source": [
    "### Check Summary Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cebb6752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL Time: 2024-10-06 14:56:50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prob_up</th>\n",
       "      <th>prob_static</th>\n",
       "      <th>prob_down</th>\n",
       "      <th>kelly_1_2</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>static</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.702929</td>\n",
       "      <td>0.760181</td>\n",
       "      <td>0.730435</td>\n",
       "      <td>[313.0, 221.0, 299.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>static</td>\n",
       "      <td>0.035975</td>\n",
       "      <td>0.95147</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>0.927205</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.714932</td>\n",
       "      <td>0.685466</td>\n",
       "      <td>[313.0, 221.0, 299.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>static</td>\n",
       "      <td>0.100786</td>\n",
       "      <td>0.77938</td>\n",
       "      <td>0.119834</td>\n",
       "      <td>0.669070</td>\n",
       "      <td>0.715481</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.743478</td>\n",
       "      <td>[313.0, 221.0, 299.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>static</td>\n",
       "      <td>0.046367</td>\n",
       "      <td>0.93997</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.909954</td>\n",
       "      <td>0.578544</td>\n",
       "      <td>0.683258</td>\n",
       "      <td>0.626556</td>\n",
       "      <td>[313.0, 221.0, 299.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model prediction   prob_up  prob_static  prob_down  kelly_1_2  \\\n",
       "0           XGBoost     static  0.000000      0.75000   0.250000   0.625000   \n",
       "1      RandomForest     static  0.035975      0.95147   0.012554   0.927205   \n",
       "2  GradientBoosting     static  0.100786      0.77938   0.119834   0.669070   \n",
       "3               KNN     static  0.046367      0.93997   0.013664   0.909954   \n",
       "\n",
       "   precision    recall        f1                support  \n",
       "0   0.702929  0.760181  0.730435  [313.0, 221.0, 299.0]  \n",
       "1   0.658333  0.714932  0.685466  [313.0, 221.0, 299.0]  \n",
       "2   0.715481  0.773756  0.743478  [313.0, 221.0, 299.0]  \n",
       "3   0.578544  0.683258  0.626556  [313.0, 221.0, 299.0]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbol='NVDA'\n",
    "interval='5m'\n",
    "period='1mo'\n",
    "\n",
    "# Define Eastern Time Zone\n",
    "eastern = pytz.timezone('US/Eastern')\n",
    "\n",
    "# Get current time in Eastern Time Zone\n",
    "eastern_time = datetime.now(eastern)\n",
    "\n",
    "# Format the time to include hour, minute, and seconds\n",
    "time_stamp = eastern_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "print(f'DL Time: {time_stamp}')\n",
    "\n",
    "# f.download(symbol, interval, period)\n",
    "f.transform(symbol, interval, period)\n",
    "curr_prediction, models, feature_names, classification_reports = f.model(symbol, interval)\n",
    "predictions, prediction_probas = f.make_prediction(models, curr_prediction, feature_names)\n",
    "\n",
    "f.predictions_summary(predictions, prediction_probas, classification_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e2f74ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBoost': np.int64(0),\n",
       " 'RandomForest': np.int64(0),\n",
       " 'GradientBoosting': np.int64(0),\n",
       " 'KNN': np.int64(0)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a2c40f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'XGBClassifier': {'0': {'precision': 0.702928870292887,\n",
       "   'recall': 0.7601809954751131,\n",
       "   'f1-score': 0.7304347826086957,\n",
       "   'support': 221.0},\n",
       "  '1': {'precision': 0.8283828382838284,\n",
       "   'recall': 0.8019169329073482,\n",
       "   'f1-score': 0.814935064935065,\n",
       "   'support': 313.0},\n",
       "  '2': {'precision': 0.7731958762886598,\n",
       "   'recall': 0.7525083612040134,\n",
       "   'f1-score': 0.7627118644067796,\n",
       "   'support': 299.0},\n",
       "  'accuracy': 0.773109243697479,\n",
       "  'macro avg': {'precision': 0.7681691949551251,\n",
       "   'recall': 0.7715354298621583,\n",
       "   'f1-score': 0.7693605706501799,\n",
       "   'support': 833.0},\n",
       "  'weighted avg': {'precision': 0.7752901269242205,\n",
       "   'recall': 0.773109243697479,\n",
       "   'f1-score': 0.7737714402626941,\n",
       "   'support': 833.0}},\n",
       " 'RandomForestClassifier': {'0': {'precision': 0.6583333333333333,\n",
       "   'recall': 0.7149321266968326,\n",
       "   'f1-score': 0.6854663774403471,\n",
       "   'support': 221.0},\n",
       "  '1': {'precision': 0.7936507936507936,\n",
       "   'recall': 0.7987220447284346,\n",
       "   'f1-score': 0.7961783439490446,\n",
       "   'support': 313.0},\n",
       "  '2': {'precision': 0.7697841726618705,\n",
       "   'recall': 0.7157190635451505,\n",
       "   'f1-score': 0.7417677642980935,\n",
       "   'support': 299.0},\n",
       "  'accuracy': 0.7466986794717887,\n",
       "  'macro avg': {'precision': 0.7405894332153324,\n",
       "   'recall': 0.7431244116568059,\n",
       "   'f1-score': 0.7411374952291618,\n",
       "   'support': 833.0},\n",
       "  'weighted avg': {'precision': 0.7491834726353714,\n",
       "   'recall': 0.7466986794717887,\n",
       "   'f1-score': 0.7472754532959155,\n",
       "   'support': 833.0}},\n",
       " 'GradientBoostingClassifier': {'0': {'precision': 0.7154811715481172,\n",
       "   'recall': 0.7737556561085973,\n",
       "   'f1-score': 0.7434782608695653,\n",
       "   'support': 221.0},\n",
       "  '1': {'precision': 0.8277027027027027,\n",
       "   'recall': 0.7827476038338658,\n",
       "   'f1-score': 0.8045977011494253,\n",
       "   'support': 313.0},\n",
       "  '2': {'precision': 0.7583892617449665,\n",
       "   'recall': 0.7558528428093646,\n",
       "   'f1-score': 0.7571189279731994,\n",
       "   'support': 299.0},\n",
       "  'accuracy': 0.7707082833133253,\n",
       "  'macro avg': {'precision': 0.7671910453319288,\n",
       "   'recall': 0.7707853675839426,\n",
       "   'f1-score': 0.7683982966640633,\n",
       "   'support': 833.0},\n",
       "  'weighted avg': {'precision': 0.7730500289553718,\n",
       "   'recall': 0.7707082833133253,\n",
       "   'f1-score': 0.7713401387466156,\n",
       "   'support': 833.0}},\n",
       " 'KNeighborsClassifier': {'0': {'precision': 0.578544061302682,\n",
       "   'recall': 0.6832579185520362,\n",
       "   'f1-score': 0.6265560165975104,\n",
       "   'support': 221.0},\n",
       "  '1': {'precision': 0.6573208722741433,\n",
       "   'recall': 0.6741214057507987,\n",
       "   'f1-score': 0.6656151419558359,\n",
       "   'support': 313.0},\n",
       "  '2': {'precision': 0.6932270916334662,\n",
       "   'recall': 0.5819397993311036,\n",
       "   'f1-score': 0.6327272727272727,\n",
       "   'support': 299.0},\n",
       "  'accuracy': 0.6434573829531812,\n",
       "  'macro avg': {'precision': 0.6430306750700971,\n",
       "   'recall': 0.6464397078779794,\n",
       "   'f1-score': 0.641632810426873,\n",
       "   'support': 833.0},\n",
       "  'weighted avg': {'precision': 0.6493092088452653,\n",
       "   'recall': 0.6434573829531812,\n",
       "   'f1-score': 0.6434476274257874,\n",
       "   'support': 833.0}}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e1d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d1fb54a",
   "metadata": {},
   "source": [
    "### Hyperparameter Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a303ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def model(symbol, interval, search_type='none'):\n",
    "    # Load data\n",
    "    data = f.load_model_df(symbol, interval)\n",
    "    data.dropna(inplace=True, axis=0)\n",
    "    X = data.drop(columns=['direction'], axis=1)\n",
    "    y = data['direction']\n",
    "    \n",
    "    # Print column names to check for issues\n",
    "    print(\"Columns in X before preprocessing:\")\n",
    "    print(X.columns)\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    X = X.loc[:, ~X.columns.duplicated()]\n",
    "    \n",
    "    # Check if categorical_features are present in X\n",
    "    categorical_features = ['day_of_month', 'day_of_week', 'hour_of_day']\n",
    "    missing_features = [col for col in categorical_features if col not in X.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Missing categorical features: {missing_features}\")\n",
    "    \n",
    "    # Store current prediction data (last row)\n",
    "    curr_prediction = X.iloc[-1].copy()\n",
    "\n",
    "    # Drop last row from X and y to prevent the model from seeing it\n",
    "    X = X.iloc[:-1]\n",
    "    y = y.iloc[:-1]\n",
    "    \n",
    "    # Create the categorical transformer\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    \n",
    "    # Create the preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        force_int_remainder_cols=False # This will include all other columns in the transformed output\n",
    "    )\n",
    "    \n",
    "    # Define your models\n",
    "    models = {\n",
    "        'XGBoost': XGBClassifier(random_state=42, n_jobs=-1),\n",
    "        'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "        'GradientBoosting': GradientBoostingClassifier(random_state=42, validation_fraction=0.25, n_iter_no_change=31),\n",
    "        # 'LightGBM': LGBMClassifier(random_state=42,force_col_wise=True),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=7, p=1,weights='distance')\n",
    "    }\n",
    "    \n",
    "    # Hyperparameters to search\n",
    "    param_grids = {\n",
    "        'XGBoost': {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [3, 5, 7, 9],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2, 0.3]\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [None, 10, 20, 30],\n",
    "            'classifier__min_samples_split': [2, 5, 10, 13]\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'classifier__n_estimators': [100, 200, 300, 400],\n",
    "            'classifier__max_depth': [3, 5, 7, 13],\n",
    "            'classifier__le||arning_rate': [0.01, 0.1, 0.2, 0.5]\n",
    "        },\n",
    "        'KNN': {\n",
    "            'classifier__n_neighbors': [3, 5, 7, 13],\n",
    "            'classifier__weights': ['uniform', 'distance'],\n",
    "            'classifier__p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create a function to get feature names after transformation\n",
    "    def get_feature_names_out(column_transformer):\n",
    "        feature_names = []\n",
    "        for name, transformer, columns in column_transformer.transformers_:\n",
    "            if transformer == 'drop' or transformer == 'passthrough':\n",
    "                if transformer == 'passthrough':\n",
    "                    feature_names.extend(columns)\n",
    "                continue\n",
    "            if hasattr(transformer, 'get_feature_names_out'):\n",
    "                names = transformer.get_feature_names_out(columns)\n",
    "                feature_names.extend(names)\n",
    "            else:\n",
    "                feature_names.extend(columns)\n",
    "        return feature_names\n",
    "    \n",
    "    # Split data before preprocessing to avoid data leakage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit the preprocessor on training data\n",
    "    preprocessor.fit(X_train)\n",
    "    \n",
    "    # Transform training and test data\n",
    "    X_train_transformed = preprocessor.transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Get feature names after transformation\n",
    "    feature_names = get_feature_names_out(preprocessor)\n",
    "    \n",
    "    # Convert transformed data to DataFrame\n",
    "    X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "    X_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_names)\n",
    "    \n",
    "    # Transform curr_prediction\n",
    "    curr_prediction_transformed = preprocessor.transform(\n",
    "        curr_prediction.to_frame().T)\n",
    "    curr_prediction_transformed = pd.DataFrame(\n",
    "        curr_prediction_transformed, columns=feature_names)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Create a pipeline with the classifier\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        # Get the parameter grid for the current model\n",
    "        param_grid = param_grids.get(model_name, {})\n",
    "        \n",
    "        # Use GridSearchCV or RandomizedSearchCV\n",
    "        if search_type == 'grid' and param_grid:\n",
    "            search = GridSearchCV(\n",
    "                pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        elif search_type == 'random' and param_grid:\n",
    "            search = RandomizedSearchCV(\n",
    "                pipeline, param_grid, cv=5, scoring='accuracy',\n",
    "                n_jobs=-1, n_iter=10, random_state=42)\n",
    "        else:\n",
    "            search = pipeline\n",
    "        \n",
    "        # Fit the model\n",
    "        search.fit(X_train_transformed, y_train)\n",
    "        \n",
    "        # If using search, get the best estimator\n",
    "        if search_type in ['grid', 'random'] and param_grid:\n",
    "            best_model = search.best_estimator_\n",
    "            print(f\"Best parameters for {model_name}: {search.best_params_}\")\n",
    "            model = best_model.named_steps['classifier']\n",
    "        else:\n",
    "            model = search.named_steps['classifier']\n",
    "        \n",
    "        # Store the model\n",
    "        models[model_name] = model\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred = search.predict(X_test_transformed)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    return curr_prediction_transformed, models, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c358417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_prediction, models, feature_names = model('AMD', '5m', 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f7294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379dcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
