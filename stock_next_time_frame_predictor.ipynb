{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc45a498-9c5a-46b8-b0c2-0cba4b368e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install Requirments (Updated on 12/17/2024)\n",
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae92876c-d015-403e-8cb5-3d49037ee40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735027043.087175  113705 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735027043.090787  113705 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is configured properly.\n",
      "Num GPUs Available: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Suppress TensorFlow logs\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'  # Use asynchronous CUDA memory allocator\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Set TensorFlow log level\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN optimizations\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Restrict TensorFlow to GPU 0\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'  # Prevent CUDA errors\n",
    "\n",
    "# Redirect STDERR to /dev/null to silence C++ warnings\n",
    "stderr = sys.stderr\n",
    "sys.stderr = open(os.devnull, 'w')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from yfinance import Ticker\n",
    "from pykalman import KalmanFilter\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "# Suppress TensorFlow and absl logs\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "logging.getLogger('absl').setLevel(logging.ERROR)\n",
    "\n",
    "# Clear previous sessions\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# GPU configuration\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"GPU is configured properly.\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error initializing GPU:\", e)\n",
    "else:\n",
    "    print(\"No GPU detected. TensorFlow will use the CPU.\")\n",
    "\n",
    "sys.stderr = stderr  # Restore STDERR\n",
    "\n",
    "# Check available GPUs\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4821df5e-9e25-4463-83ed-80f7c8d2b6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import modules as f # f is for function\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61147f2",
   "metadata": {},
   "source": [
    "### Download, Transform, and Modeling All in One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f5a4f-5fec-4117-b4fd-85444293245f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735027065.446410  113705 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1735027065.446566  113705 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13754 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "I0000 00:00:1735027069.603551  113889 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA 5m Interval Timestamp: 2024-12-24 02:57:34\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kelly_1:2.5</th>\n",
       "      <td>0.338407</td>\n",
       "      <td>0.342077</td>\n",
       "      <td>0.312941</td>\n",
       "      <td>0.216842</td>\n",
       "      <td>0.311732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_up</th>\n",
       "      <td>0.184208</td>\n",
       "      <td>0.133594</td>\n",
       "      <td>0.16936</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_static</th>\n",
       "      <td>0.662635</td>\n",
       "      <td>0.781954</td>\n",
       "      <td>0.660336</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_down</th>\n",
       "      <td>0.153157</td>\n",
       "      <td>0.084452</td>\n",
       "      <td>0.170303</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.527434</td>\n",
       "      <td>0.530055</td>\n",
       "      <td>0.509244</td>\n",
       "      <td>0.440602</td>\n",
       "      <td>0.50838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.630021</td>\n",
       "      <td>0.615222</td>\n",
       "      <td>0.640592</td>\n",
       "      <td>0.61945</td>\n",
       "      <td>0.384778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.574181</td>\n",
       "      <td>0.569472</td>\n",
       "      <td>0.567416</td>\n",
       "      <td>0.514938</td>\n",
       "      <td>0.438026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>[475.0, 473.0, 476.0]</td>\n",
       "      <td>[475.0, 473.0, 476.0]</td>\n",
       "      <td>[475.0, 473.0, 476.0]</td>\n",
       "      <td>[475.0, 473.0, 476.0]</td>\n",
       "      <td>[475.0, 473.0, 476.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           XGBoost       GradientBoosting  \\\n",
       "prediction                  static                 static   \n",
       "kelly_1:2.5               0.338407               0.342077   \n",
       "prob_up                   0.184208               0.133594   \n",
       "prob_static               0.662635               0.781954   \n",
       "prob_down                 0.153157               0.084452   \n",
       "precision                 0.527434               0.530055   \n",
       "recall                    0.630021               0.615222   \n",
       "f1                        0.574181               0.569472   \n",
       "support      [475.0, 473.0, 476.0]  [475.0, 473.0, 476.0]   \n",
       "\n",
       "                      RandomForest                    KNN  \\\n",
       "prediction                  static                 static   \n",
       "kelly_1:2.5               0.312941               0.216842   \n",
       "prob_up                    0.16936                   0.25   \n",
       "prob_static               0.660336                  0.625   \n",
       "prob_down                 0.170303                  0.125   \n",
       "precision                 0.509244               0.440602   \n",
       "recall                    0.640592                0.61945   \n",
       "f1                        0.567416               0.514938   \n",
       "support      [475.0, 473.0, 476.0]  [475.0, 473.0, 476.0]   \n",
       "\n",
       "                              LSTM  \n",
       "prediction                  static  \n",
       "kelly_1:2.5               0.311732  \n",
       "prob_up                        0.0  \n",
       "prob_static                    1.0  \n",
       "prob_down                      0.0  \n",
       "precision                  0.50838  \n",
       "recall                    0.384778  \n",
       "f1                        0.438026  \n",
       "support      [475.0, 473.0, 476.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA 15m Interval Timestamp: 2024-12-24 02:58:22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGBoost</th>\n",
       "      <th>GradientBoosting</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "      <td>static</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kelly_1:2.5</th>\n",
       "      <td>0.321472</td>\n",
       "      <td>0.349045</td>\n",
       "      <td>0.382895</td>\n",
       "      <td>0.233831</td>\n",
       "      <td>0.402667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_up</th>\n",
       "      <td>0.112323</td>\n",
       "      <td>0.096796</td>\n",
       "      <td>0.211832</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_static</th>\n",
       "      <td>0.710867</td>\n",
       "      <td>0.788857</td>\n",
       "      <td>0.547261</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob_down</th>\n",
       "      <td>0.17681</td>\n",
       "      <td>0.114347</td>\n",
       "      <td>0.240907</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.515337</td>\n",
       "      <td>0.535032</td>\n",
       "      <td>0.559211</td>\n",
       "      <td>0.452736</td>\n",
       "      <td>0.573333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.531646</td>\n",
       "      <td>0.537975</td>\n",
       "      <td>0.575949</td>\n",
       "      <td>0.272152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.523364</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.506964</td>\n",
       "      <td>0.369099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>[159.0, 158.0, 159.0]</td>\n",
       "      <td>[159.0, 158.0, 159.0]</td>\n",
       "      <td>[159.0, 158.0, 159.0]</td>\n",
       "      <td>[159.0, 158.0, 159.0]</td>\n",
       "      <td>[159.0, 158.0, 159.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           XGBoost       GradientBoosting  \\\n",
       "prediction                  static                 static   \n",
       "kelly_1:2.5               0.321472               0.349045   \n",
       "prob_up                   0.112323               0.096796   \n",
       "prob_static               0.710867               0.788857   \n",
       "prob_down                  0.17681               0.114347   \n",
       "precision                 0.515337               0.535032   \n",
       "recall                    0.531646               0.531646   \n",
       "f1                        0.523364               0.533333   \n",
       "support      [159.0, 158.0, 159.0]  [159.0, 158.0, 159.0]   \n",
       "\n",
       "                      RandomForest                    KNN  \\\n",
       "prediction                  static                 static   \n",
       "kelly_1:2.5               0.382895               0.233831   \n",
       "prob_up                   0.211832                  0.125   \n",
       "prob_static               0.547261                  0.625   \n",
       "prob_down                 0.240907                   0.25   \n",
       "precision                 0.559211               0.452736   \n",
       "recall                    0.537975               0.575949   \n",
       "f1                        0.548387               0.506964   \n",
       "support      [159.0, 158.0, 159.0]  [159.0, 158.0, 159.0]   \n",
       "\n",
       "                              LSTM  \n",
       "prediction                  static  \n",
       "kelly_1:2.5               0.402667  \n",
       "prob_up                        0.0  \n",
       "prob_static                    1.0  \n",
       "prob_down                      0.0  \n",
       "precision                 0.573333  \n",
       "recall                    0.272152  \n",
       "f1                        0.369099  \n",
       "support      [159.0, 158.0, 159.0]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f.predictions('nvda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faffd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681aeb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29e9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee10080b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9032138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73486d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b90ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c246e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bfe9c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac48269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74260a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22751626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb6752",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol='NVDA'\n",
    "interval='1d'\n",
    "\n",
    "# # Define Eastern Time Zone\n",
    "# eastern = pytz.timezone('US/Eastern')\n",
    "\n",
    "# # Get current time in Eastern Time Zone\n",
    "# eastern_time = datetime.now(eastern)\n",
    "\n",
    "# # Format the time to include hour, minute, and seconds\n",
    "# time_stamp = eastern_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# print(f'DL Time: {time_stamp}')\n",
    "\n",
    "# f.download(symbol, interval, period)\n",
    "f.transform(symbol, interval)\n",
    "curr_prediction, models, feature_names, classification_reports = f.model(symbol, interval)\n",
    "predictions, prediction_probas = f.make_prediction(models, curr_prediction, feature_names)\n",
    "\n",
    "f.predictions_summary(predictions, prediction_probas, classification_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['XGBoost'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3373277",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905656b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_list = sorted(zip(feature_names, models['XGBoost'].feature_importances_),\n",
    "                     key=lambda x: x[1], \n",
    "                     reverse=True\n",
    "                    )\n",
    "merged_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f74ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_reports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1fb54a",
   "metadata": {},
   "source": [
    "### Hyperparameter Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a303ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def model(symbol, interval, search_type='none'):\n",
    "    # Load data\n",
    "    data = f.load_model_df(symbol, interval)\n",
    "    data.dropna(inplace=True, axis=0)\n",
    "    X = data.drop(columns=['direction'], axis=1)\n",
    "    y = data['direction']\n",
    "    \n",
    "    # Print column names to check for issues\n",
    "    print(\"Columns in X before preprocessing:\")\n",
    "    print(X.columns)\n",
    "    \n",
    "    # Remove duplicate columns\n",
    "    X = X.loc[:, ~X.columns.duplicated()]\n",
    "    \n",
    "    # Check if categorical_features are present in X\n",
    "    categorical_features = ['day_of_month', 'day_of_week', 'hour_of_day']\n",
    "    missing_features = [col for col in categorical_features if col not in X.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Missing categorical features: {missing_features}\")\n",
    "    \n",
    "    # Store current prediction data (last row)\n",
    "    curr_prediction = X.iloc[-1].copy()\n",
    "\n",
    "    # Drop last row from X and y to prevent the model from seeing it\n",
    "    X = X.iloc[:-1]\n",
    "    y = y.iloc[:-1]\n",
    "    \n",
    "    # Create the categorical transformer\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    \n",
    "    # Create the preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        force_int_remainder_cols=False # This will include all other columns in the transformed output\n",
    "    )\n",
    "    \n",
    "    # Define your models\n",
    "    models = {\n",
    "        'XGBoost': XGBClassifier(random_state=42, n_jobs=-1),\n",
    "        'RandomForest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "        'GradientBoosting': GradientBoostingClassifier(random_state=42, validation_fraction=0.25, n_iter_no_change=31),\n",
    "        # 'LightGBM': LGBMClassifier(random_state=42,force_col_wise=True),\n",
    "        'KNN': KNeighborsClassifier(n_neighbors=7, p=1,weights='distance')\n",
    "    }\n",
    "    \n",
    "    # Hyperparameters to search\n",
    "    param_grids = {\n",
    "        'XGBoost': {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [3, 5, 7, 9],\n",
    "            'classifier__learning_rate': [0.01, 0.1, 0.2, 0.3]\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'classifier__n_estimators': [100, 200, 300],\n",
    "            'classifier__max_depth': [None, 10, 20, 30],\n",
    "            'classifier__min_samples_split': [2, 5, 10, 13]\n",
    "        },\n",
    "        'GradientBoosting': {\n",
    "            'classifier__n_estimators': [100, 200, 300, 400],\n",
    "            'classifier__max_depth': [3, 5, 7, 13],\n",
    "            'classifier__le||arning_rate': [0.01, 0.1, 0.2, 0.5]\n",
    "        },\n",
    "        'KNN': {\n",
    "            'classifier__n_neighbors': [3, 5, 7, 13],\n",
    "            'classifier__weights': ['uniform', 'distance'],\n",
    "            'classifier__p': [1, 2]  # 1: Manhattan, 2: Euclidean\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create a function to get feature names after transformation\n",
    "    def get_feature_names_out(column_transformer):\n",
    "        feature_names = []\n",
    "        for name, transformer, columns in column_transformer.transformers_:\n",
    "            if transformer == 'drop' or transformer == 'passthrough':\n",
    "                if transformer == 'passthrough':\n",
    "                    feature_names.extend(columns)\n",
    "                continue\n",
    "            if hasattr(transformer, 'get_feature_names_out'):\n",
    "                names = transformer.get_feature_names_out(columns)\n",
    "                feature_names.extend(names)\n",
    "            else:\n",
    "                feature_names.extend(columns)\n",
    "        return feature_names\n",
    "    \n",
    "    # Split data before preprocessing to avoid data leakage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit the preprocessor on training data\n",
    "    preprocessor.fit(X_train)\n",
    "    \n",
    "    # Transform training and test data\n",
    "    X_train_transformed = preprocessor.transform(X_train)\n",
    "    X_test_transformed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Get feature names after transformation\n",
    "    feature_names = get_feature_names_out(preprocessor)\n",
    "    \n",
    "    # Convert transformed data to DataFrame\n",
    "    X_train_transformed = pd.DataFrame(X_train_transformed, columns=feature_names)\n",
    "    X_test_transformed = pd.DataFrame(X_test_transformed, columns=feature_names)\n",
    "    \n",
    "    # Transform curr_prediction\n",
    "    curr_prediction_transformed = preprocessor.transform(\n",
    "        curr_prediction.to_frame().T)\n",
    "    curr_prediction_transformed = pd.DataFrame(\n",
    "        curr_prediction_transformed, columns=feature_names)\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        # Create a pipeline with the classifier\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        # Get the parameter grid for the current model\n",
    "        param_grid = param_grids.get(model_name, {})\n",
    "        \n",
    "        # Use GridSearchCV or RandomizedSearchCV\n",
    "        if search_type == 'grid' and param_grid:\n",
    "            search = GridSearchCV(\n",
    "                pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "        elif search_type == 'random' and param_grid:\n",
    "            search = RandomizedSearchCV(\n",
    "                pipeline, param_grid, cv=5, scoring='accuracy',\n",
    "                n_jobs=-1, n_iter=10, random_state=42)\n",
    "        else:\n",
    "            search = pipeline\n",
    "        \n",
    "        # Fit the model\n",
    "        search.fit(X_train_transformed, y_train)\n",
    "        \n",
    "        # If using search, get the best estimator\n",
    "        if search_type in ['grid', 'random'] and param_grid:\n",
    "            best_model = search.best_estimator_\n",
    "            print(f\"Best parameters for {model_name}: {search.best_params_}\")\n",
    "            model = best_model.named_steps['classifier']\n",
    "        else:\n",
    "            model = search.named_steps['classifier']\n",
    "        \n",
    "        # Store the model\n",
    "        models[model_name] = model\n",
    "        \n",
    "        # Predict on test data\n",
    "        y_pred = search.predict(X_test_transformed)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    \n",
    "    return curr_prediction_transformed, models, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c358417",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_prediction, models, feature_names = model('AMD', '5m', 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11f7294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379dcfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyenv)",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
